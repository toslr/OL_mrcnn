{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.19\n",
      "Tensorflow 2.15.0\n",
      "Num GPUs Available:  0\n",
      "Device mapping: no known devices.\n",
      "<tensorflow.python.client.session.Session object at 0x2d3ef3dc0>\n"
     ]
    }
   ],
   "source": [
    "!python3 --version\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Creates a session with device placement logs\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "print(sess)\n",
    "\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "import tifffile as tiff\n",
    "\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "from mrcnn.visualize import display_instances\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "#from custom_multi import nms_suppression_multi\n",
    "from custom import CustomConfig, CustomDataset\n",
    "from postprocessing import nms_suppression_multi, crop_from_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "num_gpu = 1 # Number of GPUs to use\n",
    "num_img_per_gpu = 1 # Batch size\n",
    "detection_min_confidence = 0.7 # Minimum confidence level for detection\n",
    "detection_nms_threshold = 0.3 # NMS threshold for detection\n",
    "\n",
    "#weights_subpath = 'multicell20240417T1006/mask_rcnn_multicell_0050.h5'\n",
    "#weights_subpath = 'grayscaleMulti/mask_rcnn_multicell_0050.h5'\n",
    "weights_subpath = 'RGBmultiBest/mask_rcnn_multicell_0050.h5'\n",
    "results_name = 'BZ_Test_gray'\n",
    "\n",
    "#TEST_DIR = '/Users/tom/Desktop/Stanford/RA/OligodendroSight/OL_mrcnn/data/test/imgsnorm'\n",
    "TEST_DIR = '/Users/tom/Downloads/BZ_OL_images_tiff_norm'\n",
    "\n",
    "VISUALIZE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading macro weights from  /Users/tom/Desktop/Stanford/RA/OligodendroSight/OL_mrcnn/logs/RGBmultiBest/mask_rcnn_multicell_0050.h5\n",
      "WARNING:tensorflow:Skipping loading weights for layer #391 (named mrcnn_bbox_fc) due to mismatch in shape for weight mrcnn_bbox_fc_7/kernel:0. Weight expects shape (1024, 8). Received saved weight with shape (1024, 20)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #391 (named mrcnn_bbox_fc) due to mismatch in shape for weight mrcnn_bbox_fc_7/bias:0. Weight expects shape (8,). Received saved weight with shape (20,)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #394 (named mrcnn_class_logits) due to mismatch in shape for weight mrcnn_class_logits_7/kernel:0. Weight expects shape (1024, 2). Received saved weight with shape (1024, 5)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #394 (named mrcnn_class_logits) due to mismatch in shape for weight mrcnn_class_logits_7/bias:0. Weight expects shape (2,). Received saved weight with shape (5,)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #396 (named mrcnn_mask) due to mismatch in shape for weight mrcnn_mask_7/kernel:0. Weight expects shape (1, 1, 256, 2). Received saved weight with shape (5, 256, 1, 1)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #396 (named mrcnn_mask) due to mismatch in shape for weight mrcnn_mask_7/bias:0. Weight expects shape (2,). Received saved weight with shape (5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:44:20.939298: W tensorflow/c/c_api.cc:305] Operation '{name:'mrcnn_mask_bn1_7/beta/Assign' id:75559 op device:{requested: '', assigned: ''} def:{{{node mrcnn_mask_bn1_7/beta/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](mrcnn_mask_bn1_7/beta, mrcnn_mask_bn1_7/beta/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfigMulti(CustomConfig):\n",
    "    GPU_COUNT = num_gpu\n",
    "    IMAGES_PER_GPU = num_img_per_gpu\n",
    "    DETECTION_MIN_CONFIDENCE = detection_min_confidence #Minimum probability value to accept a detected instance\n",
    "    DETECTION_NMS_THRESHOLD = detection_nms_threshold # Non-maximum suppression threshold for detection\n",
    "\n",
    "inference_config_multi = InferenceConfigMulti()\n",
    "macro_model = modellib.MaskRCNN(mode=\"inference\",\n",
    "                            config=inference_config_multi,\n",
    "                            model_dir=DEFAULT_LOGS_DIR)\n",
    "\n",
    "MACRO_WEIGHTS_SUBPATH = weights_subpath\n",
    "macro_model_path = os.path.join(DEFAULT_LOGS_DIR, MACRO_WEIGHTS_SUBPATH)\n",
    "\n",
    "print(\"Loading macro weights from \", macro_model_path)\n",
    "#macro_model.load_weights(macro_model_path, by_name=True) #deprecated on MacOS\n",
    "tf.keras.Model.load_weights(macro_model.keras_model, macro_model_path , by_name=True, skip_mismatch=True)\n",
    "\n",
    "RESULTS_NAME = results_name\n",
    "RESULTS_DIR = os.path.join(ROOT_DIR, \"results\", RESULTS_NAME)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "dataset_val = CustomDataset()\n",
    "dataset_val.load_custom(os.path.join(ROOT_DIR,\"data\"), \"valid\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BZ-MBL_002_20x_LatA2uM-right-28.tif\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (3,2)  and requested shape (2,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m image \u001b[38;5;241m=\u001b[39m skimage\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#gray_image = skimage.io.imread(image_path, as_gray=True)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#gray_image = (gray_image * 255).astype(np.uint8)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#image = np.stack((gray_image,)*3, axis=-1)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m macro_results \u001b[38;5;241m=\u001b[39m \u001b[43mmacro_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m macro_results \u001b[38;5;241m=\u001b[39m nms_suppression_multi(macro_results, \u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m     15\u001b[0m r \u001b[38;5;241m=\u001b[39m macro_results[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Stanford/RA/OligodendroSight/OL_mrcnn/mrcnn/model.py:2515\u001b[0m, in \u001b[0;36mMaskRCNN.detect\u001b[0;34m(self, images, verbose)\u001b[0m\n\u001b[1;32m   2512\u001b[0m         log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m, image)\n\u001b[1;32m   2514\u001b[0m \u001b[38;5;66;03m# Mold inputs to format expected by the neural network\u001b[39;00m\n\u001b[0;32m-> 2515\u001b[0m molded_images, image_metas, windows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmold_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2517\u001b[0m \u001b[38;5;66;03m# Validate image sizes\u001b[39;00m\n\u001b[1;32m   2518\u001b[0m \u001b[38;5;66;03m# All images in a batch MUST be of the same size\u001b[39;00m\n\u001b[1;32m   2519\u001b[0m image_shape \u001b[38;5;241m=\u001b[39m molded_images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/Desktop/Stanford/RA/OligodendroSight/OL_mrcnn/mrcnn/model.py:2408\u001b[0m, in \u001b[0;36mMaskRCNN.mold_inputs\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m   2404\u001b[0m windows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m   2406\u001b[0m     \u001b[38;5;66;03m# Resize image\u001b[39;00m\n\u001b[1;32m   2407\u001b[0m     \u001b[38;5;66;03m# TODO: move resizing to mold_image()\u001b[39;00m\n\u001b[0;32m-> 2408\u001b[0m     molded_image, window, scale, padding, crop \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGE_MIN_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGE_MIN_SCALE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGE_MAX_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGE_RESIZE_MODE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2414\u001b[0m     molded_image \u001b[38;5;241m=\u001b[39m mold_image(molded_image, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m   2415\u001b[0m     \u001b[38;5;66;03m# Build image_meta\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Stanford/RA/OligodendroSight/OL_mrcnn/mrcnn/utils.py:468\u001b[0m, in \u001b[0;36mresize_image\u001b[0;34m(image, min_dim, max_dim, min_scale, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m     right_pad \u001b[38;5;241m=\u001b[39m max_dim \u001b[38;5;241m-\u001b[39m w \u001b[38;5;241m-\u001b[39m left_pad\n\u001b[1;32m    467\u001b[0m     padding \u001b[38;5;241m=\u001b[39m [(top_pad, bottom_pad), (left_pad, right_pad), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)]\n\u001b[0;32m--> 468\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     window \u001b[38;5;241m=\u001b[39m (top_pad, left_pad, h \u001b[38;5;241m+\u001b[39m top_pad, w \u001b[38;5;241m+\u001b[39m left_pad)\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad64\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_test/lib/python3.9/site-packages/numpy/lib/arraypad.py:748\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`pad_width` must be of integral type.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Broadcast to shape (array.ndim, 2)\u001b[39;00m\n\u001b[0;32m--> 748\u001b[0m pad_width \u001b[38;5;241m=\u001b[39m \u001b[43m_as_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(mode):\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# Old behavior: Use user-supplied function with np.apply_along_axis\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     function \u001b[38;5;241m=\u001b[39m mode\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_test/lib/python3.9/site-packages/numpy/lib/arraypad.py:522\u001b[0m, in \u001b[0;36m_as_pairs\u001b[0;34m(x, ndim, as_index)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt contain negative values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;66;03m# Converting the array with `tolist` seems to improve performance\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# when iterating and indexing the result (see usage in `pad`)\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_test/lib/python3.9/site-packages/numpy/lib/stride_tricks.py:413\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_broadcast_to_dispatcher, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_to\u001b[39m(array, shape, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    369\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Broadcast an array to a new shape.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m           [1, 2, 3]])\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreadonly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_test/lib/python3.9/site-packages/numpy/lib/stride_tricks.py:349\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall elements of broadcast shape must be non-\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    347\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    348\u001b[0m extras \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 349\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnditer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrefs_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzerosize_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextras\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_flags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreadonly\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitershape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m it:\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;66;03m# never really has writebackifcopy semantics\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     broadcast \u001b[38;5;241m=\u001b[39m it\u001b[38;5;241m.\u001b[39mitviews[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (3,2)  and requested shape (2,2)"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "for filename in os.listdir(TEST_DIR):\n",
    "    if filename.endswith(\".tif\"):\n",
    "        image_paths.append(os.path.join(TEST_DIR, filename))\n",
    "\n",
    "res_list = []\n",
    "for image_path in image_paths:\n",
    "    print(os.path.basename(image_path))\n",
    "    image = skimage.io.imread(image_path)\n",
    "    gray_image = skimage.io.imread(image_path, as_gray=True)\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "    image = np.stack((gray_image,)*3, axis=-1)\n",
    "    macro_results = macro_model.detect([image], verbose=0)\n",
    "    macro_results = nms_suppression_multi(macro_results, 0.3)\n",
    "    r = macro_results[0]\n",
    "    if VISUALIZE:\n",
    "        display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset_val.class_names, r['scores'], \n",
    "                        title=\"Predictions\",\n",
    "                        show_bbox=True, show_mask=False)\n",
    "    img_res_dir = os.path.join(RESULTS_DIR, os.path.basename(image_path)[:-4])\n",
    "    os.makedirs(img_res_dir, exist_ok=True)\n",
    "    res_list = crop_from_results(image_path, image, img_res_dir, macro_results, res_list, dataset_val.class_names, modify_results=True)\n",
    "\n",
    "res_df = pd.DataFrame(res_list, columns=['image_name', 'detection_id', 'class', 'score', 'bbox'])\n",
    "res_df.to_csv(os.path.join(RESULTS_DIR, 'results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
