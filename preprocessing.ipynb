{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "#import pandas as pd\n",
    "import os\n",
    "import tifffile as tiff\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import czifile\n",
    "import matplotlib.pyplot as plt\n",
    "from aicsimageio import AICSImage\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CZI to TIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def czi_to_tiff(czi_folder,save_path):\n",
    "    \"\"\"read czi files and save as tiff files. CZYX -> YXC\"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for root, dirs, files in os.walk(czi_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.czi'):\n",
    "                czi = AICSImage(os.path.join(root,file))\n",
    "                image = czi.get_image_data(\"CZYX\", S=0, T=0, Z=0)\n",
    "                image = np.squeeze(image)\n",
    "                image = np.moveaxis(image, 0, -1)\n",
    "                image[...,2] = 0\n",
    "                tiff.imwrite(os.path.join(save_path,file.replace('.czi','.tif')),image[...,:3])\n",
    "\n",
    "czi_to_tiff(czi_folder='/Users/tom/Downloads/fiji-test',\n",
    "            save_path='/Users/tom/Downloads/fiji-test_tiff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def czi_to_tiff(czi_folder,save_path):\n",
    "    \"\"\"read czi files and save as tiff files. CZYX -> YXC\"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for root, dirs, files in os.walk(czi_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.czi'):\n",
    "                czi = AICSImage(os.path.join(root,file))\n",
    "                image = czi.get_image_data(\"CZYX\", S=0, T=0, Z=0)\n",
    "                image = np.squeeze(image)\n",
    "                image = np.moveaxis(image, 0, -1)\n",
    "                image[...,2] = 0\n",
    "                new_image = np.stack([image[...,0],image[...,3],np.zeros_like(image[...,0])],axis=-1)\n",
    "                tiff.imwrite(os.path.join(save_path,file.replace('.czi','.tif')),new_image)\n",
    "\n",
    "czi_to_tiff(czi_folder='/Users/tom/Downloads/fiji-test',\n",
    "            save_path='/Users/tom/Downloads/fiji-test_tifff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMETIFF to TIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ometifs_to_tifs(dir_path, save_path):\n",
    "    \"\"\"converts ome-tifs to tifs\"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file.endswith('.ome.tif'):\n",
    "            img = skimage.io.imread(os.path.join(dir_path, file))\n",
    "            for i in range(img.shape[0]):\n",
    "                skimage.io.imsave(os.path.join(save_path, file[:-8] + f'_{i}.tif'), img[i])\n",
    "\n",
    "input_path = '/Users/tom/Downloads/ometifs'\n",
    "output_path = '/Users/tom/Downloads/tifs_from_ome'\n",
    "\n",
    "ometifs_to_tifs(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and convert to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 images were normalized and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage\n",
    "folder_path = \"/Users/tom/Desktop/Stanford/RA/OligodendroSight/OL_mrcnn/data/test/imgs\"\n",
    "save_path_norm = \"/Users/tom/Desktop/Stanford/RA/OligodendroSight/OL_mrcnn/data/test/imgs_norm\"\n",
    "GRAYSCALE = False\n",
    "if not os.path.exists(save_path_norm):\n",
    "    os.makedirs(save_path_norm)\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.tif'):\n",
    "        original_img = skimage.io.imread(os.path.join(folder_path, file))\n",
    "        if GRAYSCALE:\n",
    "            float_gray_img = skimage.io.imread(os.path.join(folder_path, file), as_gray=True)\n",
    "            float_gray_img_norm = skimage.exposure.equalize_adapthist(float_gray_img, clip_limit=0.04)\n",
    "            img_norm = np.stack(((float_gray_img_norm * 255).astype(np.uint8),)*3, axis=-1)\n",
    "        else:\n",
    "            norm_channels = []\n",
    "            for i in range(original_img.shape[2]):\n",
    "                if np.max(original_img[:,:,i]) > 0:\n",
    "                    filt_channel = skimage.filters.median(original_img[:,:,i])\n",
    "                    norm_channel = skimage.exposure.equalize_adapthist(filt_channel, clip_limit=0.02)\n",
    "                    norm_channel = (norm_channel * 255).astype(np.uint8)\n",
    "                else:\n",
    "                    norm_channel = original_img[:,:,i].astype(np.uint8)\n",
    "                norm_channels.append(norm_channel)\n",
    "            img_norm = np.stack(norm_channels, axis=-1)\n",
    "        skimage.io.imsave(os.path.join(save_path_norm, os.path.basename(file)), img_norm)\n",
    "print(f'{len(os.listdir(save_path_norm))} images were normalized and saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask.tif to .json for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/tom/Desktop/Stanford/RA/OligodendroSight/datasets/Lauren/'\n",
    "img_path = os.path.join(data_path, 'Sample_TomGUI_norm')\n",
    "mask_path = os.path.join(data_path, 'masks')\n",
    "json_path = os.path.join(data_path, 'jsons')\n",
    "\n",
    "for filename in sorted(os.listdir(img_path)):\n",
    "    if filename.endswith('.tif'):\n",
    "        print(filename)\n",
    "        img = cv2.imread(os.path.join(img_path, filename))\n",
    "        mask_color = cv2.imread(os.path.join(mask_path, filename),1)\n",
    "        mask_gray = 255- cv2.imread(os.path.join(mask_path, filename),0)\n",
    "        contours, _ = cv2.findContours(mask_gray,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "        sorted_contours = sorted(contours, key=lambda x: len(x), reverse=True)\n",
    "        #print(len(sorted_contours))\n",
    "        for contour in sorted_contours:\n",
    "            if cv2.contourArea(contour) < 1000:\n",
    "                print(cv2.contourArea(contour))\n",
    "                print(contour[0][0])\n",
    "                sorted_contours.remove(contour)\n",
    "            cv2.drawContours(mask_color, [contour], -1, (0,0,255),2)\n",
    "        '''plt.figure(figsize=(15,15))\n",
    "        plt.imshow(img)\n",
    "        plt.title(filename)\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.imshow(mask_color) '''\n",
    "        shapes_dict = {'shapes': [{\"points\":[coord[0].tolist() for coord in contour],\n",
    "                           \"label\":\"cell\",\n",
    "                           \"cell number\":f\"{i+1}\"} for i, contour in enumerate(sorted_contours)],\n",
    "               'imagePath':os.path.join(img_path, filename),\n",
    "               'imageHeight':mask_gray.shape[0],\n",
    "               'imageWidth':mask_gray.shape[1]}\n",
    "        json_file = os.path.join(json_path, filename[:-4]+'.json')\n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(shapes_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / valid / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "data_folder_path = '/Users/tom/Desktop/Stanford/RA/OligodendroSight/datasets/Lauren/'\n",
    "img_folder_path = os.path.join(data_folder_path, 'Sample_TomGUI_norm')\n",
    "mask_folder_path = os.path.join(data_folder_path, 'masks')\n",
    "json_folder_path = os.path.join(data_folder_path, 'jsons')\n",
    "\n",
    "train_path = os.path.join(data_folder_path, 'train')\n",
    "valid_path = os.path.join(data_folder_path, 'valid')\n",
    "test_path = os.path.join(data_folder_path, 'test')\n",
    "\n",
    "img_train, img_else = train_test_split(os.listdir(img_folder_path), test_size=0.4, random_state=42)\n",
    "img_valid, img_test = train_test_split(img_else, test_size=0.5, random_state=42)\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    os.makedirs(train_path)\n",
    "    os.makedirs(os.path.join(train_path, 'imgs'))\n",
    "    os.makedirs(os.path.join(train_path, 'masks'))\n",
    "    os.makedirs(os.path.join(train_path, 'jsons'))\n",
    "    os.makedirs(valid_path)\n",
    "    os.makedirs(os.path.join(valid_path, 'imgs'))\n",
    "    os.makedirs(os.path.join(valid_path, 'masks'))\n",
    "    os.makedirs(os.path.join(valid_path, 'jsons'))\n",
    "    os.makedirs(test_path)\n",
    "    os.makedirs(os.path.join(test_path, 'imgs'))\n",
    "    os.makedirs(os.path.join(test_path, 'masks'))\n",
    "    os.makedirs(os.path.join(test_path, 'jsons'))\n",
    "\n",
    "for img_name in img_train:\n",
    "    if img_name[-4:] != '.tif':\n",
    "        continue\n",
    "    json_name = img_name[:-4]+'.json'\n",
    "    img_path = os.path.join(img_folder_path, img_name)\n",
    "    mask_path = os.path.join(mask_folder_path, img_name)\n",
    "    annot_path = os.path.join(json_folder_path, json_name)\n",
    "\n",
    "    shutil.move(img_path, os.path.join(train_path, 'imgs', img_name))\n",
    "    shutil.move(mask_path, os.path.join(train_path, 'masks', img_name))\n",
    "    shutil.move(annot_path, os.path.join(train_path, 'jsons', json_name))   \n",
    "\n",
    "for img_name in img_valid:\n",
    "    if img_name[-4:] != '.tif':\n",
    "        continue\n",
    "    json_name = img_name[:-4]+'.json'\n",
    "    img_path = os.path.join(img_folder_path, img_name)\n",
    "    mask_path = os.path.join(mask_folder_path, img_name)\n",
    "    annot_path = os.path.join(json_folder_path, json_name)\n",
    "\n",
    "    shutil.move(img_path, os.path.join(valid_path, 'imgs', img_name))\n",
    "    shutil.move(mask_path, os.path.join(valid_path, 'masks', img_name))\n",
    "    shutil.move(annot_path, os.path.join(valid_path, 'jsons', json_name))\n",
    "\n",
    "for img_name in img_test:\n",
    "    if img_name[-4:] != '.tif':\n",
    "        continue\n",
    "    json_name = img_name[:-4]+'.json'\n",
    "    img_path = os.path.join(img_folder_path, img_name)\n",
    "    mask_path = os.path.join(mask_folder_path, img_name)\n",
    "    annot_path = os.path.join(json_folder_path, json_name)\n",
    "\n",
    "    shutil.move(img_path, os.path.join(test_path, 'imgs', img_name))\n",
    "    shutil.move(mask_path, os.path.join(test_path, 'masks', img_name))\n",
    "    shutil.move(annot_path, os.path.join(test_path, 'jsons', json_name))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
